---
title: "Testy zgodności"
author: "Adam Michalski"
date: '2024-11-04'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE}
wzrost <- read.csv2("Wzrost.csv", header=FALSE)
colnames(wzrost) <- c("dane")
k <- 20

set.seed(1)
mu <- mean(wzrost$dane)
sigma <- sd(wzrost$dane)
normal_variable_1 <- rnorm(k, mu, sigma)

podzial_rownej_licznosci <- quantile(wzrost$dane, 0:k/k)
podzial_rownej_licznosci[1] <- min(wzrost)-5
podzial_rownej_licznosci[length(podzial_rownej_licznosci)] <- max(wzrost)+5
szereg_empiryczny <- table(cut(wzrost$dane, podzial_rownej_licznosci))
szereg_teoretyczny <- table(cut(normal_variable_1, podzial_rownej_licznosci))
chi_1 <- chisq.test(szereg_empiryczny, szereg_teoretyczny)
chi_1
```

```{r, warning=FALSE}
k <- 15
set.seed(1)
mu <- mean(wzrost$dane)
sigma <- sd(wzrost$dane)
normal_variable_2 <- rnorm(k, mu, sigma)
normal_variable_2

dlugosc_podzialu <- (min(wzrost$dane) - max(wzrost$dane))/(k-1)
podzial_rownej_dlugosci <- seq(min(wzrost$dane)-dlugosc_podzialu/2, max(wzrost$dane)+dlugosc_podzialu/2, length.out = k)
szereg_empiryczny <- table(cut(wzrost$dane, podzial_rownej_dlugosci))
szereg_teoretyczny <- table(cut(normal_variable_2, podzial_rownej_dlugosci))
chi_2 <- chisq.test(szereg_empiryczny, szereg_teoretyczny)
chi_2
```

```{r, warning=FALSE}
k <- 15
set.seed(1)
random_noise <- runif(length(wzrost$dane), -0.5, 0.5)
data_with_noise <- wzrost$dane+random_noise
szereg_empiryczny <- table(cut(data_with_noise, podzial_rownej_dlugosci))
dlugosc_podzialu <- (min(data_with_noise) - max(data_with_noise))/(k-1)
podzial_rownej_dlugosci <- seq(min(data_with_noise)-dlugosc_podzialu/2, max(data_with_noise)+dlugosc_podzialu/2, length.out = k)
szereg_empiryczny <- table(cut(data_with_noise, podzial_rownej_dlugosci))
szereg_teoretyczny <- table(cut(normal_variable_2, podzial_rownej_dlugosci))
chi_3 <- chisq.test(szereg_empiryczny, szereg_teoretyczny)
chi_3
```

```{r, warning=FALSE}
library(DescTools)

shapiro_wilk_basic <- shapiro.test(wzrost$dane)
shapiro_wilk_basic
shapiro_wilk_noise <- shapiro.test(data_with_noise)
shapiro_wilk_noise

lilliefors_basic <- LillieTest(wzrost$dane)
lilliefors_basic
lilliefors_noise <- LillieTest(data_with_noise)
lilliefors_noise
```
Zaburzenie danych losową zmienną jednostajną zwiększa p-value w przypadku każdego z tych testów na normalność, lecz ma kluczowe znaczenie dla testu Kołomogorowa-Smirnowa, którego statystyka mierząca odległość między dystrybuantą teoretyczną, a empiryczną maleje przy pozbyciu się zaokrągleń do liczb całkowitych w badanych danych.

```{r, warning=FALSE}
library(readxl)

stopy <- read_excel("Stopa.xls")
names(stopy) <- c("lewa stopa", "prawa stopa")
dane_1 <- lapply(stopy[6:25, ], as.numeric)
dane_1
dane_2 <- lapply(stopy[31:50, ], as.numeric)
dane_2

chisq.test(dane_1$`lewa stopa`, dane_1$`prawa stopa`)
chisq.test(dane_2$`lewa stopa`, dane_2$`prawa stopa`)
```
W pierwszym modelu doświadczenia możemy przeprowadzić test równości średniej dwóch niezależnych próbek za pomocą t-testu:
```{r}
t.test(dane_1$`lewa stopa`, dane_1$`prawa stopa`, alternative = "greater", mu = 0)
```
W przypadku drugiego modelu, skoro pomiary z odpowiednich próbek dobrane są w pary możemy skorzystać z t-testu badającego hipotezę o zerowej różnicy par pomiarów z odpowiednich danych.
```{r}
t.test(dane_2$`lewa stopa`, dane_2$`prawa stopa`, alternative = "greater", mu = 0, paired = TRUE)
```
Pierwszy profesor poczynił założenie o braku związku pomiędzy  pomiarami długości lewej i prawej stopy tej samem osoby rozważając pomiary stóp różnych osób . Lepszym modelem wydaje się być model jednak pomysł drugiego profesora, rozważający pomiary obu stóp wybranych losowo osób, gdyż to podejście uwzględnia związaną z badanym problemem silną zależność pomiędzy pomiarami lewej, a prawej stopy tej samej osoby uzasadnionej przez przeprowadzony test $\chi^2$ niezależności. Uwzględnienie zależności pomiędzy pomiarami obu stóp u tych samych osób pozwala też zmniejszyć wariancję pomiarów. Przeprowadzone testy dla obu danych nie wykazują jednak istotnej dodatniej różnicy między długością prawych i lewych stóp.

```{r}
ks.test(dane_1$`lewa stopa`, dane_1$`prawa stopa`)
ks.test(dane_2$`lewa stopa`, dane_2$`prawa stopa`)
```
Na podstawie p-value przy każdym ze sposobów zbierania danych nie mamy podstaw do odrzucenia hipotezy o tym samym rozkładzie próbek złożonych z pomiarów odpowiednio lewych i prawych stóp.
